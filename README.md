#  Найди инвестора

Этот проект посвящен предсказанию принятия инвестиционных предложений клиентами банка с использованием машинного обучения. Проект включает в себя исследовательский анализ данных (EDA), обучение нескольких моделей и их ансамблирование для достижения наилучшей точности предсказания.

## Описание проекта

Цель проекта — предсказать, примет ли клиент инвестиционное предложение банка (бинарная классификация). В проекте используются различные алгоритмы машинного обучения, включая CatBoost, Random Forest, Logistic Regression, SVM и их комбинации через стекинг и бустинг.

## Структура проекта

```
├── eda.ipynb              # Исследовательский анализ данных
├── train.ipynb            # Обучение моделей и подбор гиперпараметров
├── predict.ipynb          # Предсказание на тестовых данных
└── README.md              # Документация проекта
```

## Данные

### Статистика данных

- **Обучающая выборка**: 6000 записей
- **Тестовая выборка**: 1000 записей
- **Распределение целевой переменной**: 
  - Класс 1 (принял): 4352 записей (72.5%)
  - Класс 0 (отклонил): 1648 записей (27.5%)

## Исследовательский анализ данных (EDA)

Файл: **`eda.ipynb`**

В этом ноутбуке проводится:

- **Загрузка и первичный осмотр данных**
- **Статистический анализ**:
  - Описательная статистика числовых признаков
  - Распределение категориальных признаков
  - Анализ пропущенных значений
- **Визуализация данных**:
  - Гистограммы распределений
  - Корреляционный анализ
  - Анализ связи признаков с целевой переменной
- **Предобработка данных**:
  - One-Hot Encoding для категориальных признаков
  - Стандартизация числовых признаков (StandardScaler)
  - Сохранение обработанных данных в `train_final.csv` и `test_final.csv`

### Ключевые наблюдения из EDA

- Данные не содержат пропущенных значений
- Числовые признаки имеют различные масштабы, требуется нормализация
- Категориальные признаки преобразованы в dummy-переменные
- Целевая переменная имеет дисбаланс классов (72.5% vs 27.5%)

## Обучение моделей

Файл: **`train.ipynb`**

### Используемые алгоритмы

1. **CatBoost Classifier**
   - Обучение на необработанных данных (с категориальными признаками)
   - Обучение на обработанных данных (после preprocessing)
   - Гиперпараметры подобраны через GridSearchCV

2. **Random Forest Classifier**
   - Две версии модели с различными гиперпараметрами
   - RF1: оптимизирована для точности
   - RF2: оптимизирована для стекинга

3. **Logistic Regression**
   - Базовая модель для сравнения
   - Настройка регуляризации (L1/L2)

4. **Support Vector Machine (SVM)**
   - Kernel: linear, RBF
   - Подбор параметров C, gamma через GridSearch

### Ансамблирование моделей

#### Стекинг 1: CatBoost + RF1 + LogReg → Meta-модель (Logistic Regression)
- **Метрики валидации**: 
  - Accuracy: 0.7792
  - Precision: 0.8002
  - Recall: 0.9278
  - F1-Score: 0.8593

#### Стекинг 2: CatBoost + RF1 + RF2 → Meta-модель (SVM)
- **Метрики валидации**: 
  - Accuracy: 0.7808
  - Precision: 0.7988
  - Recall: 0.9335
  - F1-Score: 0.8609

#### Стекинг 3: SVM + XGBoost
- SVM предсказания используются как дополнительные признаки для XGBoost
- Показывает хорошую стабильность на тесте

### Результаты лучших моделей

| Модель | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| CatBoost (processed) | 0.7867 | 0.8263 | 0.8945 | 0.8590 |
| Random Forest 1 | 0.7758 | 0.7976 | 0.9266 | 0.8573 |
| SVM (linear) | 0.7900 | 0.8229 | 0.9060 | 0.8624 |
| **Stacking (SVM meta)** | **0.7808** | **0.7988** | **0.9335** | **0.8609** |

## Предсказание на тесте

Файл: **`predict.ipynb`**

В этом ноутбуке:

1. **Загрузка обученных моделей** из сохраненных файлов (`.pkl`)
2. **Загрузка тестовых данных**
3. **Применение различных стратегий предсказания**:
   - Стекинг 1 (CatBoost + RF1 + LogReg)
   - Стекинг 2 (CatBoost + RF1 + RF2 + SVM meta)
   - SVM standalone
   - SVM + XGBoost
4. **Генерация submission файла**
5. **Итоговый скоринг на финальном тесте: 96.68**
### Использование

```python
# Загрузка модели
catboost_loaded = joblib.load('models/catboost_model.pkl')
rf1_loaded = joblib.load('models/random_forest_model1.pkl')
meta_loaded = joblib.load('models/meta_model.pkl')

# Предсказание
boost_proba_test = catboost_loaded.predict_proba(test_df)[:, 1]
rf1_proba_test = rf1_loaded.predict_proba(X_test)[:, 1]
test_predictions = np.column_stack([boost_proba_test, rf1_proba_test])

final_proba_test = meta_loaded.predict_proba(test_predictions)[:, 1]
y_pred_test = (final_proba_test > 0.5).astype(int)

# Сохранение результата
submission_pd['accepted'] = y_pred_test
submission_pd.to_csv('submission_42.csv')
```

## Установка и запуск

### Требования

```bash
pip install pandas numpy matplotlib seaborn scikit-learn catboost xgboost joblib
```

### Версии библиотек

- Python: 3.12+
- pandas: 2.2.2+
- numpy: 2.0.2+
- scikit-learn: 1.5.0+
- catboost: 1.2.8+
- xgboost: 3.0.5+

### Запуск проекта

1. **Выполните EDA**: откройте и запустите `eda.ipynb`
2. **Обучите модели**: запустите `train.ipynb`
3. **Сделайте предсказания**: запустите `predict.ipynb`

## Метрики качества

Основные метрики для оценки:
- **Accuracy**: общая точность классификации
- **Precision**: точность положительных предсказаний
- **Recall**: полнота положительных предсказаний
- **F1-Score**: гармоническое среднее Precision и Recall

Приоритет отдавался **F1-Score**, так как данные имеют дисбаланс классов.

## Возможные улучшения

- [ ] Feature Engineering: создание новых признаков
- [ ] Обработка дисбаланса классов (SMOTE, class_weight)
- [ ] Hyperparameter Tuning с Optuna или Bayesian Optimization
- [ ] Использование Deep Learning моделей (Neural Networks)
- [ ] Ensembling через Voting Classifier
- [ ] Cross-validation стратегии (StratifiedKFold)

## Примечания

- Все модели сохранены в формате `.pkl` для переиспользования
- Seed для воспроизводимости: `42`
- Проект выполнен в Google Colab с использованием Google Drive для хранения данных

## Авторы

Проект выполнен автором в рамках соревнования от Sber уровня BASE по машинному обучению на платформе RuCode.

## Лицензия

Проект создан в образовательных целях.

---

